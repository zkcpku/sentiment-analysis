{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import progressbar\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from SenTree import *\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "class RecursiveNN(nn.Module):\n",
    "    def __init__(self, vocabSize, embedSize=100, numClasses=5):\n",
    "        super(RecursiveNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(int(vocabSize), embedSize)\n",
    "        self.W = nn.Linear(2*embedSize, embedSize, bias=True)\n",
    "        self.projection = nn.Linear(embedSize, numClasses, bias=True) # 对每个节点进行五分类的预测，将其softmax即为各个种类的概率\n",
    "        self.activation = nn.ReLU()\n",
    "        self.nodeProbList = [] # 用来存储各个节点的概率值\n",
    "        self.labelList = [] # 用来存储各个节点的正确值\n",
    "        self.crossentropy = nn.CrossEntropyLoss()\n",
    "\n",
    "    def traverse(self, node):\n",
    "        '''\n",
    "        用来递归地获取每个节点的概率值\n",
    "        并保存在nodeProbList\n",
    "        并将对应的label值存在labelList中\n",
    "        返回输入node的激活值\n",
    "        '''\n",
    "        if node.isLeaf(): currentNode = self.activation(self.embedding(Var(torch.LongTensor([node.getLeafWord()])))) \n",
    "        # 对于叶节点，直接计算embedding后的激活值，即f(a)\n",
    "        else: currentNode = self.activation(self.W(torch.cat((self.traverse(node.left()),self.traverse(node.right())),1)))\n",
    "        # 否则将左右节点连接(cat)，在经过一个线性层，即f(W * [a b])，相当于这里的父节点的embedding为[a b]\n",
    "        self.nodeProbList.append(self.projection(currentNode))\n",
    "        self.labelList.append(torch.LongTensor([node.label()]))\n",
    "        return currentNode\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        前向传播 返回各个节点的预测值\n",
    "        '''\n",
    "        self.nodeProbList = []\n",
    "        self.labelList = []\n",
    "        self.traverse(x)\n",
    "        self.labelList = Var(torch.cat(self.labelList))\n",
    "        return torch.cat(self.nodeProbList)\n",
    "\n",
    "    def getLoss(self, tree):\n",
    "        nodes = self.forward(tree)\n",
    "        predictions = nodes.max(dim=1)[1]\n",
    "        loss = self.crossentropy(input = nodes, target = self.labelList)\n",
    "#         loss = F.cross_entropy(input=nodes, target=self.labelList)\n",
    "        return predictions,loss\n",
    "\n",
    "    def evaluate(self, trees):\n",
    "        pbar = progressbar.ProgressBar(widgets=widgets, maxval=len(trees)).start()\n",
    "        n = nAll = correctRoot = correctAll = 0.0\n",
    "        for j, tree in enumerate(trees):\n",
    "            predictions,loss = self.getLoss(tree)\n",
    "            correct = (predictions.data==self.labelList.data)\n",
    "            correctAll += correct.sum()\n",
    "            nAll += correct.squeeze().size()[0]\n",
    "            correctRoot += correct.squeeze()[-1]\n",
    "            n += 1\n",
    "            pbar.update(j)\n",
    "        pbar.finish()\n",
    "        return correctRoot.item() / n, correctAll.item() /nAll\n",
    "\n",
    "def Var(v):\n",
    "    if CUDA: return Variable(v.cuda())\n",
    "    else: return Variable(v)\n",
    "    \n",
    "# 使用save保存模型，并转换到cpu上保存，使用的时候在转换到gpu上\n",
    "def save_model(model, filename):\n",
    "    state = model.state_dict()\n",
    "    for key in state: state[key] = state[key].clone().cpu()\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeLSTM(nn.Module):\n",
    "    def __init__(self, vocabSize, hdim=100, numClasses=5):\n",
    "        super(TreeLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(int(vocabSize), hdim)\n",
    "        self.Wi = nn.Linear(hdim, hdim, bias=True)\n",
    "        self.Wo = nn.Linear(hdim, hdim, bias=True)\n",
    "        self.Wu = nn.Linear(hdim, hdim, bias=True)\n",
    "        self.Ui = nn.Linear(2 * hdim, hdim, bias=True)\n",
    "        self.Uo = nn.Linear(2 * hdim, hdim, bias=True)\n",
    "        self.Uu = nn.Linear(2 * hdim, hdim, bias=True)\n",
    "        self.Uf1 = nn.Linear(hdim, hdim, bias=True)\n",
    "        self.Uf2 = nn.Linear(hdim, hdim, bias=True)\n",
    "        self.projection = nn.Linear(hdim, numClasses, bias=True)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.nodeProbList = []\n",
    "        self.labelList = []\n",
    "        self.crossentropy = nn.CrossEntropyLoss()\n",
    "        \n",
    "\n",
    "    def traverse(self, node):\n",
    "        if node.isLeaf():\n",
    "            e = self.embedding(Var(torch.LongTensor([node.getLeafWord()])))\n",
    "            i = torch.sigmoid(self.Wi(e))\n",
    "            o = torch.sigmoid(self.Wo(e))\n",
    "            u = self.activation(self.Wu(e))\n",
    "            c = i * u\n",
    "        else:\n",
    "            leftH,leftC = self.traverse(node.left())\n",
    "            rightH,rightC = self.traverse(node.right())\n",
    "            e = torch.cat((leftH, rightH), 1)\n",
    "            i = torch.sigmoid(self.Ui(e))\n",
    "            o = torch.sigmoid(self.Uo(e))\n",
    "            u = self.activation(self.Uu(e))\n",
    "            c = i * u + torch.sigmoid(self.Uf1(leftH)) * leftC + torch.sigmoid(self.Uf2(rightH)) * rightC # 新的记忆\n",
    "        h = o * self.activation(c)\n",
    "        self.nodeProbList.append(self.projection(h))\n",
    "        self.labelList.append(torch.LongTensor([node.label()]))\n",
    "        return h,c\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.nodeProbList = []\n",
    "        self.labelList = []\n",
    "        self.traverse(x)\n",
    "        self.labelList = Var(torch.cat(self.labelList))\n",
    "        return torch.cat(self.nodeProbList)\n",
    "\n",
    "    def getLoss(self, tree):\n",
    "        nodes = self.forward(tree)\n",
    "        predictions = nodes.max(dim=1)[1]\n",
    "        loss = self.crossentropy(input=nodes, target=self.labelList)\n",
    "        return predictions,loss\n",
    "\n",
    "    def evaluate(self, trees):\n",
    "        pbar = progressbar.ProgressBar(widgets=widgets, maxval=len(trees)).start()\n",
    "        n = nAll = correctRoot = correctAll = 0.0\n",
    "        for j, tree in enumerate(trees):\n",
    "            predictions,loss = self.getLoss(tree)\n",
    "            correct = (predictions.data==self.labelList.data)\n",
    "            correctAll += correct.sum()\n",
    "            nAll += correct.squeeze().size()[0]\n",
    "            correctRoot += correct.squeeze()[-1]\n",
    "            n += 1\n",
    "            pbar.update(j)\n",
    "        pbar.finish()\n",
    "        return correctRoot.item() / n, correctAll.item()/nAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and parsing trees\n"
     ]
    }
   ],
   "source": [
    "CUDA=True\n",
    "if len(sys.argv)>1:\n",
    "    if sys.argv[1].lower()==\"cuda\": CUDA=True\n",
    "\n",
    "print(\"Reading and parsing trees\")\n",
    "# trn = SenTree.getTrees(\"./trees/train.txt\",\"train.vocab\") # 第一次解析的时候需要生成词向量\n",
    "trn = SenTree.getTrees(\"./trees/train.txt\",vocabIndicesMapFile=\"train.vocab\") # 修改后\n",
    "dev = SenTree.getTrees(\"./trees/dev.txt\",vocabIndicesMapFile=\"train.vocab\")\n",
    "\n",
    "max_epochs = 100\n",
    "widgets = [progressbar.Percentage(), ' ', progressbar.Bar(), ' ', progressbar.ETA()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:02\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14623069936421434\n",
      "0.07959562815161532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if CUDA: model = TreeLSTM(SenTree.vocabSize).cuda()\n",
    "# else: model = RecursiveNN(SenTree.vocabSize)\n",
    "correctRoot, correctAll = model.evaluate(dev)\n",
    "print(correctRoot)\n",
    "print(correctAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, dampening=0.0)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr = 0.005)\n",
    "bestAll=bestRoot=0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use_old_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use old model?(y)y\n",
      "15_16test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:01\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010899182561307902\n",
      "0.6486356069196806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "use_old_model = input(\"use old model?(y)\")\n",
    "if use_old_model == 'y':\n",
    "    model = TreeLSTM(SenTree.vocabSize)\n",
    "    model_name = input()\n",
    "#     model_name = 'model/' + model_name + '.model'\n",
    "    model.load_state_dict(torch.load('model/' + model_name + '.model'))\n",
    "    model = model.cuda()\n",
    "    correctRoot, correctAll = model.evaluate(dev)\n",
    "    print(correctRoot)\n",
    "    print(correctAll)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, dampening=0.0)\n",
    "    optimizer.load_state_dict(torch.load('model/opt_'+ model_name + '.opt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = ReduceLROnPlateau(optimizer,'max', factor = 0.2, patience = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReduceLROnPlateau?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 6 * 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:25:40\n",
      "100% |##########################################################| Time: 0:01:02\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.565903442951239(best:0.565903442951239)\n",
      "Validation Root accuracy:0.1298819255222525(best:0.1298819255222525)\n",
      "epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:26:59\n",
      "100% |##########################################################| Time: 0:01:07\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.7336839819528554(best:0.7336839819528554)\n",
      "Validation Root accuracy:0.1226158038147139(best:0.1298819255222525)\n",
      "epoch:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:25:16\n",
      "100% |##########################################################| Time: 0:01:02\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.7671001520013512(best:0.7671001520013512)\n",
      "Validation Root accuracy:0.14713896457765668(best:0.14713896457765668)\n",
      "epoch:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:25:13\n",
      "100% |##########################################################| Time: 0:01:02\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.7786812073250174(best:0.7786812073250174)\n",
      "Validation Root accuracy:0.16530426884650318(best:0.16530426884650318)\n",
      "epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:25:13\n",
      "100% |##########################################################| Time: 0:01:02\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.759596593239559(best:0.7786812073250174)\n",
      "Validation Root accuracy:0.16893732970027248(best:0.16893732970027248)\n",
      "epoch:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:25:04\n",
      "100% |##########################################################| Time: 0:01:02\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.7837479190291216(best:0.7837479190291216)\n",
      "Validation Root accuracy:0.1589464123524069(best:0.16893732970027248)\n",
      "epoch:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:25:03\n",
      "100% |##########################################################| Time: 0:01:01\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.7588486500832389(best:0.7837479190291216)\n",
      "Validation Root accuracy:0.16076294277929154(best:0.16893732970027248)\n",
      "epoch:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:25:03\n",
      "100% |##########################################################| Time: 0:01:02\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.768909691895674(best:0.7837479190291216)\n",
      "Validation Root accuracy:0.18982742960944596(best:0.18982742960944596)\n",
      "epoch:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:25:27\n",
      "100% |##########################################################| Time: 0:01:05\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.7688373102999011(best:0.7837479190291216)\n",
      "Validation Root accuracy:0.17892824704813806(best:0.18982742960944596)\n",
      "epoch:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:26:24\n",
      "100% |##########################################################| Time: 0:01:04\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.7719979733153184(best:0.7837479190291216)\n",
      "Validation Root accuracy:0.1916439600363306(best:0.1916439600363306)\n",
      "epoch:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:26:31\n",
      "100% |##########################################################| Time: 0:01:03\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.7766062682461939(best:0.7837479190291216)\n",
      "Validation Root accuracy:0.19255222524977295(best:0.19255222524977295)\n",
      "epoch:  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:25:42\n",
      "100% |##########################################################| Time: 0:01:03\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.775641180302555(best:0.7837479190291216)\n",
      "Validation Root accuracy:0.18891916439600362(best:0.19255222524977295)\n",
      "epoch:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:25:44\n",
      "100% |##########################################################| Time: 0:01:03\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.7742659299828697(best:0.7837479190291216)\n",
      "Validation Root accuracy:0.1907356948228883(best:0.19255222524977295)\n",
      "epoch:  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:26:42\n",
      "100% |##########################################################| Time: 0:01:06\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.7737833860110502(best:0.7837479190291216)\n",
      "Validation Root accuracy:0.1880108991825613(best:0.19255222524977295)\n",
      "epoch:  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:26:14\n",
      "100% |##########################################################| Time: 0:01:08\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.7723840084927739(best:0.7837479190291216)\n",
      "Validation Root accuracy:0.1771117166212534(best:0.19255222524977295)\n",
      "epoch:  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:26:26\n",
      "100% |##########################################################| Time: 0:01:03\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.773952276401187(best:0.7837479190291216)\n",
      "Validation Root accuracy:0.18346957311534967(best:0.19255222524977295)\n",
      "epoch:  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:25:36\n",
      "100% |##########################################################| Time: 0:01:03\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.7724563900885468(best:0.7837479190291216)\n",
      "Validation Root accuracy:0.17801998183469572(best:0.19255222524977295)\n",
      "epoch:  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:25:44\n",
      "100% |##########################################################| Time: 0:01:03\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.7732525876420488(best:0.7837479190291216)\n",
      "Validation Root accuracy:0.18528610354223432(best:0.19255222524977295)\n",
      "epoch:  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:25:24\n",
      "100% |##########################################################| Time: 0:01:02\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.7734697324293677(best:0.7837479190291216)\n",
      "Validation Root accuracy:0.1807447774750227(best:0.19255222524977295)\n",
      "epoch:  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:26:17\n",
      "100% |##########################################################| Time: 0:01:06\n",
      "  0% |                                                         | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation All-nodes accuracy:0.7735179868265496(best:0.7837479190291216)\n",
      "Validation Root accuracy:0.18346957311534967(best:0.19255222524977295)\n",
      "epoch:  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39% |#######################                                   | ETA:  0:15:59\r"
     ]
    }
   ],
   "source": [
    "for e in range(max_epochs):\n",
    "    print(\"epoch: \", e)\n",
    "    pbar = progressbar.ProgressBar(widgets=widgets, maxval=len(trn)).start()\n",
    "    for step, tree in enumerate(trn):\n",
    "#         print(step)\n",
    "        predictions, loss = model.getLoss(tree) # 对每棵树计算loss\n",
    "        writer.add_scalar('plot/loss',loss,step + 1 + e * len(trn))\n",
    "        optimizer.zero_grad() # \n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), 5) # 梯度裁剪，防止爆掉https://www.cnblogs.com/lindaxin/p/7998196.html\n",
    "        optimizer.step()\n",
    "        pbar.update(step)\n",
    "    pbar.finish()\n",
    "    correctRoot, correctAll = model.evaluate(dev)\n",
    "#     if bestAll<correctAll: bestAll=correctAll\n",
    "#     if bestRoot<correctRoot: bestRoot=correctRoot\n",
    "    \n",
    "    writer.add_scalar('plot/lr', optimizer.param_groups[0]['lr'], e + 1)\n",
    "    scheduler.step(correctAll)\n",
    "    if bestAll < correctAll:\n",
    "        bestAll = correctAll\n",
    "#         bestAll_model = model # 只是引用。。。\n",
    "        save_model(model,'run_model/bestAll_model.model')\n",
    "    if bestRoot<correctRoot:\n",
    "        bestRoot = correctRoot\n",
    "#         bestRoot_model = model # 只是引用。。。\n",
    "        save_model(model,'run_model/bestRoot_model.model')\n",
    "    print(\"\\nValidation All-nodes accuracy:\"+str(correctAll)+\"(best:\"+str(bestAll)+\")\")\n",
    "    print(\"Validation Root accuracy:\" + str(correctRoot)+\"(best:\"+str(bestRoot)+\")\")\n",
    "    random.shuffle(trn) # 随机排列 # 随机梯度下降"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:02\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05449591280653951\n",
      "0.7269766207445654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correctRoot, correctAll = model.evaluate(dev)\n",
    "print(correctRoot)\n",
    "print(correctAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestAll_model = TreeLSTM(SenTree.vocabSize)\n",
    "bestAll_model.load_state_dict(torch.load('run_model/bestAll_model.model'))\n",
    "bestAll_model = bestAll_model.cuda()\n",
    "correctRoot, correctAll = bestAll_model.evaluate(dev)\n",
    "print(correctRoot)\n",
    "print(correctAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestRoot_model = TreeLSTM(SenTree.vocabSize)\n",
    "bestRoot_model.load_state_dict(torch.load('run_model/bestRoot_model.model'))\n",
    "bestRoot_model = bestRoot_model.cuda()\n",
    "correctRoot, correctAll = bestRoot_model.evaluate(dev)\n",
    "print(correctRoot)\n",
    "print(correctAll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15_16test\n",
      "model/15_16test.model\n"
     ]
    }
   ],
   "source": [
    "save_model_name = input()\n",
    "no_list = '\\/:*?\"\"<>|'\n",
    "print('model/' + save_model_name + '.model')\n",
    "for e in no_list:\n",
    "    if e in save_model_name:\n",
    "        print(\"error name!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, 'model/' + save_model_name + '.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(optimizer.state_dict(),'model/opt_'+ save_model_name + '.opt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer.load_state_dict(torch.load('model/opt_'+ save_model_name + '.opt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use old model?(y)y\n",
      "15_16test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:02\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05449591280653951\n",
      "0.7269766207445654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# use_old_model = input(\"use old model?(y)\")\n",
    "# if use_old_model == 'y':\n",
    "#     old_model = TreeLSTM(SenTree.vocabSize)\n",
    "#     model_name = input()\n",
    "#     model_name = 'model/' + model_name + '.model'\n",
    "#     old_model.load_state_dict(torch.load(model_name))\n",
    "#     old_model = old_model.cuda()\n",
    "#     correctRoot, correctAll = old_model.evaluate(dev)\n",
    "#     print(correctRoot)\n",
    "#     print(correctAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 保存模型\n",
    "# import pickle\n",
    "# with open('model/model_rlstm','wb') as f:\n",
    "#     pickle.dump(model,f)\n",
    "# with open('model/optimizer_rlstm','wb') as f:\n",
    "#     pickle.dump(optimizer,f)\n",
    "# with open('model/scheduler_rlstm','wb') as f:\n",
    "#     pickle.dump(scheduler,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入模型\n",
    "# import pickle\n",
    "# with open('model/model','rb') as f:\n",
    "#     old_model = pickle.load(f)\n",
    "# old_model = old_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:00:20\n"
     ]
    }
   ],
   "source": [
    "correctRoot, correctAll = old_model.evaluate(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11625794732061762 0.7159987453856733\n"
     ]
    }
   ],
   "source": [
    "print(correctRoot,correctAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctAll.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bestAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2, device='cuda:0', dtype=torch.uint8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bestRoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2, device='cuda:0', dtype=torch.uint8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctRoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0', dtype=torch.uint8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bestRoot<correctRoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(model.labelList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1, device='cuda:0', dtype=torch.uint8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctRoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 1, 1, 2, 1, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 1, 2, 0, 2, 1, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 1, 1, 2, 1], device='cuda:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.labelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(model.labelList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(dev[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(model.nodeProbList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-1.8794,  0.3595,  3.0406,  0.9783, -2.2877]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-2.2810,  0.1816,  3.4546,  0.6747, -2.4519]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-2.2362, -0.4725,  4.1145,  0.1757, -1.9254]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-1.9478, -0.8599,  2.1633,  1.3635, -0.5603]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-1.3765, -0.5862,  4.0972, -0.0786, -1.9582]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-2.7018, -0.6171,  3.1411,  0.6767, -1.4938]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-1.8839,  0.7276,  2.3320,  0.9264, -2.5472]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-1.4892,  0.3374,  1.7578,  0.6994, -1.3117]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-1.9381,  0.1946,  3.6418,  0.0094, -1.9506]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.1261,  0.5602,  2.3632, -0.3496, -2.3496]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-2.2362, -0.4725,  4.1145,  0.1757, -1.9254]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-3.4456, -0.5500,  4.9093,  1.2386, -1.3084]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-2.2386, -0.3675,  2.9028,  0.4377, -0.1677]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.0703,  0.3329,  1.6183, -0.5959, -1.8925]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-2.2487,  0.3247,  3.0476,  0.4387, -1.7265]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-1.5775,  0.6223,  1.7728,  0.5999, -1.8320]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-3.4416,  0.7038,  3.0970,  0.0816, -0.6747]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-1.4288,  0.2090,  1.9174,  0.6519, -1.2996]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-1.6667,  0.5058,  2.4681,  0.2186, -1.4787]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-1.5526,  0.2963,  1.8883,  0.4612, -1.4218]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-1.4682,  0.4166,  1.8732,  0.8145, -1.6295]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.6835,  0.5853,  1.2005,  0.3990, -1.5653]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.9621,  0.9785,  1.9636,  0.3102, -2.2753]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.6081,  0.9223,  0.9524,  0.2616, -1.5874]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.8540,  0.6356,  1.3619,  0.5050, -1.6811]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.7456,  0.4985,  0.4881,  0.7150, -1.0877]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.4732,  0.5676,  0.6853,  0.5450, -1.0273]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-2.4081, -0.6700,  4.5894,  0.3171, -2.0435]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-1.3179,  0.3868,  1.2831,  0.6898, -1.1813]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-2.9405, -0.1622,  5.4741,  0.8223, -1.1960]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-1.1233,  0.6418,  1.0816,  0.5406, -1.0264]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-1.6097, -0.7524,  4.0182,  0.3849, -2.2104]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-3.2998,  0.9027,  2.7910,  0.7048, -0.4383]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-1.7678,  0.1963,  3.8385, -0.3534, -1.8994]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-2.7998,  0.4561,  1.3958,  1.6975, -0.4221]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-2.5586, -0.4102,  2.4542,  1.5640, -1.5499]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-1.6706,  0.4030,  2.1250,  0.7067, -1.8444]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-2.4424, -0.5265,  3.0252,  0.4936, -0.8573]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-2.1644, -0.6309,  4.3135, -0.1114, -2.6428]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.0703,  0.3329,  1.6183, -0.5959, -1.8925]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-1.5062, -0.1047,  3.2944, -0.2933, -1.7882]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-2.8403,  0.0142,  4.8940,  0.1641, -2.5714]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-2.1644, -0.6309,  4.3135, -0.1114, -2.6428]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-1.2817, -0.7013,  0.8141,  1.4882,  0.2354]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-1.1766, -0.3768,  3.4485, -0.0256, -1.5248]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-1.2770, -0.0801,  0.9906,  0.3509, -0.1894]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-1.5367,  0.0746,  1.7328,  0.4576, -0.9094]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-1.7448,  0.2644,  2.4881,  0.6577, -1.5360]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-1.5169,  0.4728,  2.1150,  0.3592, -1.5813]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-1.4385,  0.3302,  1.6345,  0.4980, -1.4192]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.9266,  0.6950,  1.0779,  0.3989, -1.1497]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.4837,  0.6086,  0.6864,  0.3829, -1.0472]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.1187,  0.4113,  0.3300,  0.2656, -0.6792]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-2.5976, -0.1043,  5.8495,  0.2533, -3.4361]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.1905,  0.4941,  0.1048,  0.4187, -0.3221]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.nodeProbList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8794,  0.3595,  3.0406,  0.9783, -2.2877],\n",
       "        [-2.2810,  0.1816,  3.4546,  0.6747, -2.4519],\n",
       "        [-2.2362, -0.4725,  4.1145,  0.1757, -1.9254],\n",
       "        [-1.9478, -0.8599,  2.1633,  1.3635, -0.5603],\n",
       "        [-1.3765, -0.5862,  4.0972, -0.0786, -1.9582],\n",
       "        [-2.7018, -0.6171,  3.1411,  0.6767, -1.4938],\n",
       "        [-1.8839,  0.7276,  2.3320,  0.9264, -2.5472],\n",
       "        [-1.4892,  0.3374,  1.7578,  0.6994, -1.3117],\n",
       "        [-1.9381,  0.1946,  3.6418,  0.0094, -1.9506],\n",
       "        [-0.1261,  0.5602,  2.3632, -0.3496, -2.3496],\n",
       "        [-2.2362, -0.4725,  4.1145,  0.1757, -1.9254],\n",
       "        [-3.4456, -0.5500,  4.9093,  1.2386, -1.3084],\n",
       "        [-2.2386, -0.3675,  2.9028,  0.4377, -0.1677],\n",
       "        [-0.0703,  0.3329,  1.6183, -0.5959, -1.8925],\n",
       "        [-2.2487,  0.3247,  3.0476,  0.4387, -1.7265],\n",
       "        [-1.5775,  0.6223,  1.7728,  0.5999, -1.8320],\n",
       "        [-3.4416,  0.7038,  3.0970,  0.0816, -0.6747],\n",
       "        [-1.4288,  0.2090,  1.9174,  0.6519, -1.2996],\n",
       "        [-1.6667,  0.5058,  2.4681,  0.2186, -1.4787],\n",
       "        [-1.5526,  0.2963,  1.8883,  0.4612, -1.4218],\n",
       "        [-1.4682,  0.4166,  1.8732,  0.8145, -1.6295],\n",
       "        [-0.6835,  0.5853,  1.2005,  0.3990, -1.5653],\n",
       "        [-0.9621,  0.9785,  1.9636,  0.3102, -2.2753],\n",
       "        [-0.6081,  0.9223,  0.9524,  0.2616, -1.5874],\n",
       "        [-0.8540,  0.6356,  1.3619,  0.5050, -1.6811],\n",
       "        [-0.7456,  0.4985,  0.4881,  0.7150, -1.0877],\n",
       "        [-0.4732,  0.5676,  0.6853,  0.5450, -1.0273],\n",
       "        [-2.4081, -0.6700,  4.5894,  0.3171, -2.0435],\n",
       "        [-1.3179,  0.3868,  1.2831,  0.6898, -1.1813],\n",
       "        [-2.9405, -0.1622,  5.4741,  0.8223, -1.1960],\n",
       "        [-1.1233,  0.6418,  1.0816,  0.5406, -1.0264],\n",
       "        [-1.6097, -0.7524,  4.0182,  0.3849, -2.2104],\n",
       "        [-3.2998,  0.9027,  2.7910,  0.7048, -0.4383],\n",
       "        [-1.7678,  0.1963,  3.8385, -0.3534, -1.8994],\n",
       "        [-2.7998,  0.4561,  1.3958,  1.6975, -0.4221],\n",
       "        [-2.5586, -0.4102,  2.4542,  1.5640, -1.5499],\n",
       "        [-1.6706,  0.4030,  2.1250,  0.7067, -1.8444],\n",
       "        [-2.4424, -0.5265,  3.0252,  0.4936, -0.8573],\n",
       "        [-2.1644, -0.6309,  4.3135, -0.1114, -2.6428],\n",
       "        [-0.0703,  0.3329,  1.6183, -0.5959, -1.8925],\n",
       "        [-1.5062, -0.1047,  3.2944, -0.2933, -1.7882],\n",
       "        [-2.8403,  0.0142,  4.8940,  0.1641, -2.5714],\n",
       "        [-2.1644, -0.6309,  4.3135, -0.1114, -2.6428],\n",
       "        [-1.2817, -0.7013,  0.8141,  1.4882,  0.2354],\n",
       "        [-1.1766, -0.3768,  3.4485, -0.0256, -1.5248],\n",
       "        [-1.2770, -0.0801,  0.9906,  0.3509, -0.1894],\n",
       "        [-1.5367,  0.0746,  1.7328,  0.4576, -0.9094],\n",
       "        [-1.7448,  0.2644,  2.4881,  0.6577, -1.5360],\n",
       "        [-1.5169,  0.4728,  2.1150,  0.3592, -1.5813],\n",
       "        [-1.4385,  0.3302,  1.6345,  0.4980, -1.4192],\n",
       "        [-0.9266,  0.6950,  1.0779,  0.3989, -1.1497],\n",
       "        [-0.4837,  0.6086,  0.6864,  0.3829, -1.0472],\n",
       "        [-0.1187,  0.4113,  0.3300,  0.2656, -0.6792],\n",
       "        [-2.5976, -0.1043,  5.8495,  0.2533, -3.4361],\n",
       "        [-0.1905,  0.4941,  0.1048,  0.4187, -0.3221]], device='cuda:0',\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cat(model.nodeProbList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plist = torch.cat(model.nodeProbList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 1, 2, 1], device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plist.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 1, 2, 1], device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plist.max(dim = 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 1, 1, 2, 1, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 1, 2, 0, 2, 1, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 1, 1, 2, 1], device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.labelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = plist.max(dim = 1)[1] ==model.labelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 1], device='cuda:0', dtype=torch.uint8)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(38, device='cuda:0')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# s.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict = plist.max(dim = 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 1, 2, 1], device='cuda:0')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 1], device='cuda:0', dtype=torch.uint8)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict.data == model.labelList.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = nAll = correctAll = correctRoot = 0.0\n",
    "\n",
    "# for j, tree in enumerate(dev):\n",
    "#     predictions, loss = model.getLoss(tree)\n",
    "#     correct = (predictions.data == model.labelList.data)\n",
    "#     correctAll += correct.sum()\n",
    "#     nAll += correct.squeeze().size()[0]\n",
    "#     correctRoot += correct.squeeze()[-1]\n",
    "#     n += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 1], device='cuda:0', dtype=torch.uint8)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(82, device='cuda:0', dtype=torch.uint8)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctRoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1101.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(29517, device='cuda:0')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41447.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7121625208097088"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctAll.item() / nAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07447774750227067"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctRoot.item() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9491, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Tensor.backward of tensor(0.9491, device='cuda:0', grad_fn=<NllLossBackward>)>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss.backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
