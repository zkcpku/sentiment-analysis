{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parameters import *\n",
    "from model import *\n",
    "from dataloader import SenTree,trn,dev,vocab_size\n",
    "\n",
    "\n",
    "from nltk.parse.corenlp import CoreNLPParser\n",
    "from nltk import Tree\n",
    "from functools import reduce\n",
    "from nltk.treeprettyprinter import TreePrettyPrinter\n",
    "from nltk.draw.tree import TreeView\n",
    "\n",
    "model_path = opt.model_path\n",
    "\n",
    "\n",
    "net = TreeLSTM(vocab_size)\n",
    "checkpoint = torch.load(model_path)\n",
    "\n",
    "net.load_state_dict(checkpoint['net'])\n",
    "\n",
    "if opt.evaluate_use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    net.to(device)\n",
    "\n",
    "'''\n",
    "start dataloader\n",
    "'''\n",
    "class SenTreeTest(ParentedTree):\n",
    "    def __init__(self, node, children=None):\n",
    "        super(SenTreeTest,self).__init__(node, children)\n",
    "\n",
    "    def left(self):\n",
    "        return self[0]\n",
    "\n",
    "    def right(self):\n",
    "        return self[1]\n",
    "\n",
    "    def isLeaf(self):\n",
    "        return self.height()==2\n",
    "\n",
    "    def getLeafWord(self):\n",
    "        return self[0]\n",
    "    def getTree(tree, vocabIndicesMapFile =opt.vocab_path):\n",
    "        tree = SenTreeTest.fromstring(tree)\n",
    "        vocabIndicesMap=cPickle.load(open(vocabIndicesMapFile,'rb'))\n",
    "        SenTreeTest.mapTreeNodes(tree,vocabIndicesMap)\n",
    "        index = 0\n",
    "        for subtree in tree.subtrees():\n",
    "            subtree.set_label(index)\n",
    "            index += 1\n",
    "        return tree\n",
    "    def mapTreeNodes(tree, vocabIndicesMap):\n",
    "        for leafPos in tree.treepositions('leaves'):\n",
    "            if tree[leafPos] in vocabIndicesMap: tree[leafPos] = vocabIndicesMap[tree[leafPos]]\n",
    "            else: tree[leafPos]= vocabIndicesMap['UNK']\n",
    "                \n",
    "    def index2str(tree, vocabIndicesMapFile = opt.vocab_path):\n",
    "        index2str = {}\n",
    "        vocabIndicesMap=cPickle.load(open(vocabIndicesMapFile,'rb'))\n",
    "        for k in vocabIndicesMap:\n",
    "            index2str[vocabIndicesMap[k]] = k\n",
    "        for leafPos in tree.treepositions('leaves'):\n",
    "            tree[leafPos] = index2str[tree[leafPos]]\n",
    "        return tree\n",
    "def binarize(tree):\n",
    "    \"\"\"\n",
    "    Recursively turn a tree into a binary tree.\n",
    "    \"\"\"\n",
    "    if isinstance(tree, str):\n",
    "        return Tree('0',[tree])\n",
    "    elif len(tree) == 1:\n",
    "#         print(tree)\n",
    "#         print('\\n')\n",
    "        return binarize(tree[0])\n",
    "    else:\n",
    "        label = tree.label()\n",
    "#         print(type(label))\n",
    "        return reduce(lambda x, y: Tree(label, (binarize(x), binarize(y))), tree)\n",
    "\n",
    "\n",
    "parser = CoreNLPParser(url='http://localhost:8000')\n",
    "'''\n",
    "ending dataloader\n",
    "'''\n",
    "\n",
    "def evaluate_train(data_iter):\n",
    "    net.eval()\n",
    "    data_correctRoot,data_correctAll = net.evaluate(data_iter)\n",
    "    print(\"correctRoot :\",data_correctRoot)\n",
    "    print(\"correctAll  :\",data_correctAll)\n",
    "\n",
    "    return data_correctRoot,data_correctAll\n",
    "\n",
    "\n",
    "def showInput(my_sentence,draw_pic = False):\n",
    "    t, = parser.raw_parse(my_sentence)\n",
    "    # t.draw()\n",
    "    bt = binarize(t)\n",
    "    # bt.draw()\n",
    "    tree = bt.pformat()\n",
    "    input = SenTreeTest.getTree(tree)\n",
    "    # input.draw()\n",
    "    net.eval()\n",
    "\n",
    "    # print(type(dev[0]))\n",
    "    # print(type(input))\n",
    "    predictions, loss = net.getLoss(input)\n",
    "    scores = net.forward(input).cpu().detach().numpy()\n",
    "    scores_exp = np.exp(scores)\n",
    "    possi = scores_exp / scores_exp.sum(axis = 1).reshape(-1,1)\n",
    "    root_possi = possi[-1]\n",
    "    root_class = np.argmax(root_possi)\n",
    "    # print((predictions.data))\n",
    "    # print((net.labelList.data))\n",
    "    pred = predictions.data\n",
    "    label = net.labelList.data\n",
    "    index2scores = {}\n",
    "    for i in range(len(pred)):\n",
    "        p = pred[i].item()\n",
    "        p_list = [\"very negative\",\"negative\",\"neutral\",\"positive\",\"very positive\"]\n",
    "#         p_list = [\"--\",\"-\",\"0\",\"+\",\"++\"]\n",
    "        index2scores[label[i].item()] = p_list[p]\n",
    "    for subtree in input.subtrees():\n",
    "        i = subtree.label()\n",
    "        subtree.set_label(index2scores[i])\n",
    "    input.index2str()\n",
    "    if draw_pic:\n",
    "        input.draw()\n",
    "        input.pretty_print()\n",
    "    outimage = TreePrettyPrinter(input)\n",
    "    outimage = str(outimage)\n",
    "\n",
    "\n",
    "    return outimage,root_possi,root_class\n",
    "\n",
    "\n",
    "def generate_csv(test_path,save_path):\n",
    "    test_csv = pd.read_csv(test_path,sep = \"\\t\")\n",
    "    phrase_id = test_csv['PhraseId'].values\n",
    "    strings = test_csv['Phrase']\n",
    "\n",
    "    rst = []\n",
    "    net.eval()\n",
    "    for e in strings:\n",
    "        rst.append(showInput(e)[2])\n",
    "\n",
    "    rst = np.array(rst, dtype = int)\n",
    "\n",
    "    final_answer = pd.DataFrame({'PhraseId':phrase_id,'Sentiment':rst})\n",
    "\n",
    "    final_answer.to_csv(save_path,index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = pd.read_csv(\"test.tsv\",sep = \"\\t\")\n",
    "phrase_id = test_csv['PhraseId'].values\n",
    "strings = test_csv['Phrase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66292"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = showInput(strings[0])\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      negative                                 \n",
      "                                                 ________|_________________________________     \n",
      "                                             negative                                      |   \n",
      "               _________________________________|_________________                         |    \n",
      "              |                                                neutral                     |   \n",
      "              |                                  _________________|_______                 |    \n",
      "           neutral                              |                      negative            |   \n",
      "    __________|___________                      |                  _______|________        |    \n",
      "   |                   neutral                  |              neutral             |       |   \n",
      "   |           ___________|__________           |         ________|_______         |       |    \n",
      "neutral    neutral             very positive neutral  neutral          neutral  neutral neutral\n",
      "   |          |                      |          |        |                |        |       |    \n",
      "   An   intermittently            pleasing     but     mostly          routine   effort    .   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TreeLSTM(\n",
       "  (embedding): Embedding(18281, 100)\n",
       "  (Wi): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (Wo): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (Wu): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (Ui): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (Uo): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (Uu): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (Uf1): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (Uf2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (projection): Linear(in_features=100, out_features=5, bias=True)\n",
       "  (activation): ReLU()\n",
       "  (crossentropy): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rst = []\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:108: RuntimeWarning: overflow encountered in exp\n",
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:109: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "for e in strings:\n",
    "    try:\n",
    "        tmp = showInput(e)\n",
    "        rst.append(tmp[2])\n",
    "    except:\n",
    "        error.append(e)\n",
    "        rst.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "66292\n"
     ]
    }
   ],
   "source": [
    "print(len(error))\n",
    "print(len(rst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66292"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phrase_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_answer = pd.DataFrame({'PhraseId':phrase_id,'Sentiment':rst})\n",
    "final_answer.to_csv(\"rst.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8544"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1101"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |##########################################################| Time: 0:01:13\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correctRoot : 0.07538601271571299\n",
      "correctAll  : 0.7652906121070282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.07538601271571299, 0.7652906121070282)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_train(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = ['boring','not boring','not so boring','interes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        very positive            \n",
      "    __________|____________       \n",
      "neutral                 positive \n",
      "   |                       |      \n",
      "   so                 interesting\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(showInput(\"so interesting\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(showInput(\"not so boring\")[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
