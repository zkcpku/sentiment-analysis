{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import progressbar\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from SenTree import *\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "class RecursiveNN(nn.Module):\n",
    "    def __init__(self, vocabSize, embedSize=100, numClasses=5):\n",
    "        super(RecursiveNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(int(vocabSize), embedSize)\n",
    "        self.W = nn.Linear(2*embedSize, embedSize, bias=True)\n",
    "        self.projection = nn.Linear(embedSize, numClasses, bias=True) # 对每个节点进行五分类的预测，将其softmax即为各个种类的概率\n",
    "        self.activation = nn.ReLU()\n",
    "        self.nodeProbList = [] # 用来存储各个节点的概率值\n",
    "        self.labelList = [] # 用来存储各个节点的正确值\n",
    "        self.crossentropy = nn.CrossEntropyLoss()\n",
    "\n",
    "    def traverse(self, node):\n",
    "        '''\n",
    "        用来递归地获取每个节点的概率值\n",
    "        并保存在nodeProbList\n",
    "        并将对应的label值存在labelList中\n",
    "        返回输入node的激活值\n",
    "        '''\n",
    "        if node.isLeaf(): currentNode = self.activation(self.embedding(Var(torch.LongTensor([node.getLeafWord()])))) \n",
    "        # 对于叶节点，直接计算embedding后的激活值，即f(a)\n",
    "        else: currentNode = self.activation(self.W(torch.cat((self.traverse(node.left()),self.traverse(node.right())),1)))\n",
    "        # 否则将左右节点连接(cat)，在经过一个线性层，即f(W * [a b])，相当于这里的父节点的embedding为[a b]\n",
    "        self.nodeProbList.append(self.projection(currentNode))\n",
    "        self.labelList.append(torch.LongTensor([node.label()]))\n",
    "        return currentNode\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        前向传播 返回各个节点的预测值\n",
    "        '''\n",
    "        self.nodeProbList = []\n",
    "        self.labelList = []\n",
    "        self.traverse(x)\n",
    "        self.labelList = Var(torch.cat(self.labelList))\n",
    "        return torch.cat(self.nodeProbList)\n",
    "\n",
    "    def getLoss(self, tree):\n",
    "        nodes = self.forward(tree)\n",
    "        predictions = nodes.max(dim=1)[1]\n",
    "        loss = self.crossentropy(input = nodes, target = self.labelList)\n",
    "#         loss = F.cross_entropy(input=nodes, target=self.labelList)\n",
    "        return predictions,loss\n",
    "\n",
    "    def evaluate(self, trees):\n",
    "        pbar = progressbar.ProgressBar(widgets=widgets, maxval=len(trees)).start()\n",
    "        n = nAll = correctRoot = correctAll = 0.0\n",
    "        for j, tree in enumerate(trees):\n",
    "            predictions,loss = self.getLoss(tree)\n",
    "            correct = (predictions.data==self.labelList.data)\n",
    "            correctAll += correct.sum()\n",
    "            nAll += correct.squeeze().size()[0]\n",
    "            correctRoot += correct.squeeze()[-1]\n",
    "            n += 1\n",
    "            pbar.update(j)\n",
    "        pbar.finish()\n",
    "        return correctRoot.item() / n, correctAll.item() /nAll\n",
    "\n",
    "def Var(v):\n",
    "    if CUDA: return Variable(v.cuda())\n",
    "    else: return Variable(v)\n",
    "    \n",
    "# 使用save保存模型，并转换到cpu上保存，使用的时候在转换到gpu上\n",
    "def save_model(model, filename):\n",
    "    state = model.state_dict()\n",
    "    for key in state: state[key] = state[key].clone().cpu()\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeLSTM(nn.Module):\n",
    "    def __init__(self, vocabSize, hdim=100, numClasses=5):\n",
    "        super(TreeLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(int(vocabSize), hdim)\n",
    "        self.Wi = nn.Linear(hdim, hdim, bias=True)\n",
    "        self.Wo = nn.Linear(hdim, hdim, bias=True)\n",
    "        self.Wu = nn.Linear(hdim, hdim, bias=True)\n",
    "        self.Ui = nn.Linear(2 * hdim, hdim, bias=True)\n",
    "        self.Uo = nn.Linear(2 * hdim, hdim, bias=True)\n",
    "        self.Uu = nn.Linear(2 * hdim, hdim, bias=True)\n",
    "        self.Uf1 = nn.Linear(hdim, hdim, bias=True)\n",
    "        self.Uf2 = nn.Linear(hdim, hdim, bias=True)\n",
    "        self.projection = nn.Linear(hdim, numClasses, bias=True)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.nodeProbList = []\n",
    "        self.labelList = []\n",
    "        self.crossentropy = nn.CrossEntropyLoss()\n",
    "        \n",
    "\n",
    "    def traverse(self, node):\n",
    "        if node.isLeaf():\n",
    "            e = self.embedding(Var(torch.LongTensor([node.getLeafWord()])))\n",
    "            i = torch.sigmoid(self.Wi(e))\n",
    "            o = torch.sigmoid(self.Wo(e))\n",
    "            u = self.activation(self.Wu(e))\n",
    "            c = i * u\n",
    "        else:\n",
    "            leftH,leftC = self.traverse(node.left())\n",
    "            rightH,rightC = self.traverse(node.right())\n",
    "            e = torch.cat((leftH, rightH), 1)\n",
    "            i = torch.sigmoid(self.Ui(e))\n",
    "            o = torch.sigmoid(self.Uo(e))\n",
    "            u = self.activation(self.Uu(e))\n",
    "            c = i * u + torch.sigmoid(self.Uf1(leftH)) * leftC + torch.sigmoid(self.Uf2(rightH)) * rightC\n",
    "        h = o * self.activation(c)\n",
    "        self.nodeProbList.append(self.projection(h))\n",
    "        self.labelList.append(torch.LongTensor([node.label()]))\n",
    "        return h,c\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.nodeProbList = []\n",
    "        self.labelList = []\n",
    "        self.traverse(x)\n",
    "        self.labelList = Var(torch.cat(self.labelList))\n",
    "        return torch.cat(self.nodeProbList)\n",
    "\n",
    "    def getLoss(self, tree):\n",
    "        nodes = self.forward(tree)\n",
    "        predictions = nodes.max(dim=1)[1]\n",
    "        loss = self.crossentropy(input=nodes, target=self.labelList)\n",
    "        return predictions,loss\n",
    "\n",
    "    def evaluate(self, trees):\n",
    "        pbar = progressbar.ProgressBar(widgets=widgets, maxval=len(trees)).start()\n",
    "        n = nAll = correctRoot = correctAll = 0.0\n",
    "        for j, tree in enumerate(trees):\n",
    "            predictions,loss = self.getLoss(tree)\n",
    "            correct = (predictions.data==self.labelList.data)\n",
    "            correctAll += correct.sum()\n",
    "            nAll += correct.squeeze().size()[0]\n",
    "            correctRoot += correct.squeeze()[-1]\n",
    "            n += 1\n",
    "            pbar.update(j)\n",
    "        pbar.finish()\n",
    "        return correctRoot.item() / n, correctAll.item()/nAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and parsing trees\n"
     ]
    }
   ],
   "source": [
    "CUDA=True\n",
    "if len(sys.argv)>1:\n",
    "    if sys.argv[1].lower()==\"cuda\": CUDA=True\n",
    "\n",
    "print(\"Reading and parsing trees\")\n",
    "# trn = SenTree.getTrees(\"./trees/train.txt\",\"train.vocab\") # 第一次解析的时候需要生成词向量\n",
    "trn = SenTree.getTrees(\"./trees/train.txt\",vocabIndicesMapFile=\"train.vocab\") # 修改后\n",
    "dev = SenTree.getTrees(\"./trees/dev.txt\",vocabIndicesMapFile=\"train.vocab\")\n",
    "\n",
    "widgets = [progressbar.Percentage(), ' ', progressbar.Bar(), ' ', progressbar.ETA()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use_old_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use old model?(y)y\n",
      "4_15_rst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76% |############################################              | ETA:  0:00:17\r"
     ]
    }
   ],
   "source": [
    "use_old_model = input(\"use old model?(y)\")\n",
    "if use_old_model == 'y':\n",
    "    model = TreeLSTM(SenTree.vocabSize)\n",
    "    model_name = input()\n",
    "#     model_name = 'model/' + model_name + '.model'\n",
    "    model.load_state_dict(torch.load('model/' + model_name + '.model'))\n",
    "    model = model.cuda()\n",
    "    correctRoot, correctAll = model.evaluate(dev)\n",
    "    print(correctRoot)\n",
    "    print(correctAll)\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, dampening=0.0)\n",
    "#     optimizer.load_state_dict(torch.load('model/opt_'+ model_name + '.opt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tree import ParentedTree\n",
    "import _pickle as cPickle\n",
    "\n",
    "class SenTreeTest(ParentedTree):\n",
    "    def __init__(self, node, children=None):\n",
    "        super(SenTreeTest,self).__init__(node, children)\n",
    "\n",
    "    def left(self):\n",
    "        return self[0]\n",
    "\n",
    "    def right(self):\n",
    "        return self[1]\n",
    "\n",
    "    def isLeaf(self):\n",
    "        return self.height()==2\n",
    "\n",
    "    def getLeafWord(self):\n",
    "        return self[0]\n",
    "    def getTree(tree, vocabIndicesMapFile =\"train.vocab\"):\n",
    "        tree = SenTreeTest.fromstring(tree)\n",
    "        vocabIndicesMap=cPickle.load(open(vocabIndicesMapFile,'rb'))\n",
    "        SenTreeTest.mapTreeNodes(tree,vocabIndicesMap)\n",
    "        index = 0\n",
    "        for subtree in tree.subtrees():\n",
    "            subtree.set_label(index)\n",
    "            index += 1\n",
    "        return tree\n",
    "    def mapTreeNodes(tree, vocabIndicesMap):\n",
    "        for leafPos in tree.treepositions('leaves'):\n",
    "            if tree[leafPos] in vocabIndicesMap: tree[leafPos] = vocabIndicesMap[tree[leafPos]]\n",
    "            else: tree[leafPos]= vocabIndicesMap['UNK']\n",
    "                \n",
    "    def index2str(tree, vocabIndicesMapFile = \"train.vocab\"):\n",
    "        index2str = {}\n",
    "        vocabIndicesMap=cPickle.load(open(vocabIndicesMapFile,'rb'))\n",
    "        for k in vocabIndicesMap:\n",
    "            index2str[vocabIndicesMap[k]] = k\n",
    "        for leafPos in tree.treepositions('leaves'):\n",
    "            tree[leafPos] = index2str[tree[leafPos]]\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse.corenlp import CoreNLPParser\n",
    "from nltk import Tree\n",
    "from functools import reduce\n",
    "from nltk.treeprettyprinter import TreePrettyPrinter\n",
    "def binarize(tree):\n",
    "    \"\"\"\n",
    "    Recursively turn a tree into a binary tree.\n",
    "    \"\"\"\n",
    "    if isinstance(tree, str):\n",
    "        return Tree('0',[tree])\n",
    "    elif len(tree) == 1:\n",
    "#         print(tree)\n",
    "#         print('\\n')\n",
    "        return binarize(tree[0])\n",
    "    else:\n",
    "        label = tree.label()\n",
    "#         print(type(label))\n",
    "        return reduce(lambda x, y: Tree(label, (binarize(x), binarize(y))), tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = CoreNLPParser(url='http://localhost:8000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sentence = \"I love you.\"\n",
    "t, = parser.raw_parse(my_sentence)\n",
    "# t.draw()\n",
    "bt = binarize(t)\n",
    "# bt.draw()\n",
    "tree = bt.pformat()\n",
    "input = SenTreeTest.getTree(tree)\n",
    "# input.draw()\n",
    "model.eval()\n",
    "\n",
    "# print(type(dev[0]))\n",
    "# print(type(input))\n",
    "predictions, loss = model.getLoss(input)\n",
    "# print((predictions.data))\n",
    "# print((model.labelList.data))\n",
    "pred = predictions.data\n",
    "label = model.labelList.data\n",
    "index2scores = {}\n",
    "for i in range(len(pred)):\n",
    "    p = pred[i].item()\n",
    "#     p_list = [\"very negative\",\"negative\",\"neutral\",\"positive\",\"very positive\"]\n",
    "    p_list = [\"--\",\"-\",\"0\",\"+\",\"++\"]\n",
    "    index2scores[label[i].item()] = p_list[p]\n",
    "#     index2scores[label[i].item()] = p\n",
    "for subtree in input.subtrees():\n",
    "    i = subtree.label()\n",
    "    subtree.set_label(index2scores[i])\n",
    "input.index2str()\n",
    "input.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showInput(my_sentence):\n",
    "    t, = parser.raw_parse(my_sentence)\n",
    "    # t.draw()\n",
    "    bt = binarize(t)\n",
    "    # bt.draw()\n",
    "    tree = bt.pformat()\n",
    "    input = SenTreeTest.getTree(tree)\n",
    "    # input.draw()\n",
    "    model.eval()\n",
    "\n",
    "    # print(type(dev[0]))\n",
    "    # print(type(input))\n",
    "    predictions, loss = model.getLoss(input)\n",
    "    # print((predictions.data))\n",
    "    # print((model.labelList.data))\n",
    "    pred = predictions.data\n",
    "    label = model.labelList.data\n",
    "    index2scores = {}\n",
    "    for i in range(len(pred)):\n",
    "        p = pred[i].item()\n",
    "        p_list = [\"very negative\",\"negative\",\"neutral\",\"positive\",\"very positive\"]\n",
    "#         p_list = [\"--\",\"-\",\"0\",\"+\",\"++\"]\n",
    "        index2scores[label[i].item()] = p_list[p]\n",
    "    for subtree in input.subtrees():\n",
    "        i = subtree.label()\n",
    "        subtree.set_label(index2scores[i])\n",
    "    input.index2str()\n",
    "    input.draw()\n",
    "    input.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         positive                                    \n",
      "                    ________|____________________________________     \n",
      "                positive                                         |   \n",
      "    _______________|________                                     |    \n",
      "   |                     positive                                |   \n",
      "   |        ________________|___________                         |    \n",
      "   |       |                      very positive                  |   \n",
      "   |       |                 ___________|_____________           |    \n",
      "neutral neutral          positive               very positive neutral\n",
      "   |       |                |                         |          |    \n",
      "   I       am             truly                     happy        .   \n",
      "\n",
      "                      positive                \n",
      "               __________|________________     \n",
      "           positive                       |   \n",
      "    __________|__________                 |    \n",
      "   |                  positive            |   \n",
      "   |           __________|________        |    \n",
      "neutral very positive          neutral neutral\n",
      "   |          |                   |       |    \n",
      "   I         love                you      .   \n",
      "\n",
      "                        very positive                \n",
      "                    __________|__________________     \n",
      "                neutral                          |   \n",
      "    _______________|__________                   |    \n",
      "   |                       positive              |   \n",
      "   |                __________|__________        |    \n",
      "   |            neutral                  |       |   \n",
      "   |        _______|__________           |       |    \n",
      "neutral neutral            neutral    neutral neutral\n",
      "   |       |                  |          |       |    \n",
      "   I     really              like        it      .   \n",
      "\n",
      "                neutral                 \n",
      "            _______|________________     \n",
      "        neutral                     |   \n",
      "    _______|_______                 |    \n",
      "   |            positive            |   \n",
      "   |        _______|________        |    \n",
      "neutral neutral          neutral neutral\n",
      "   |       |                |       |    \n",
      "   I      like              it      .   \n",
      "\n",
      "                                        neutral                         \n",
      "                            _______________|________________________     \n",
      "                        neutral                                     |   \n",
      "    _______________________|_______                                 |    \n",
      "   |                            neutral                             |   \n",
      "   |                _______________|_______________                 |    \n",
      "   |            neutral                         positive            |   \n",
      "   |        _______|_______                 _______|________        |    \n",
      "neutral neutral         neutral         neutral          neutral neutral\n",
      "   |       |               |               |                |       |    \n",
      "   I       do             n't             like              it      .   \n",
      "\n",
      "                      negative                \n",
      "               __________|________________     \n",
      "           neutral                        |   \n",
      "    __________|__________                 |    \n",
      "   |                  negative            |   \n",
      "   |           __________|________        |    \n",
      "neutral very negative          neutral neutral\n",
      "   |          |                   |       |    \n",
      "   I         hate                you      .   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\"I am truly happy.\",\"I love you.\",\"I really like it.\",\"I like it.\",\"I don't like it.\",\"I hate you.\"]\n",
    "for s in test_sentences:\n",
    "    showInput(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "tensor([2, 4, 6, 7, 5, 3, 1, 8, 0], device='cuda:0')\n",
      "             0             \n",
      "          ___|___________   \n",
      "         0               | \n",
      "  _______|___            |  \n",
      " |           0           | \n",
      " |    _______|___        |  \n",
      " |   |           0       | \n",
      " |   |        ___|___    |  \n",
      " 0   0       0       0   0 \n",
      " |   |       |       |   |  \n",
      " He  is      a      boy  . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 导出字符图到字符串\n",
    "from nltk.draw.tree import TreeView\n",
    "my_sentence = \"He is a boy.\"\n",
    "t, = parser.raw_parse(my_sentence)\n",
    "# t.draw()\n",
    "bt = binarize(t)\n",
    "# bt.draw()\n",
    "tree = bt.pformat()\n",
    "input = SenTreeTest.getTree(tree)\n",
    "input.draw()\n",
    "model.eval()\n",
    "\n",
    "# print(type(dev[0]))\n",
    "# print(type(input))\n",
    "predictions, loss = model.getLoss(input)\n",
    "print((predictions.data))\n",
    "print((model.labelList.data))\n",
    "pred = predictions.data\n",
    "label = model.labelList.data\n",
    "index2scores = {}\n",
    "for i in range(len(pred)):\n",
    "    p = pred[i].item()\n",
    "#     p_list = [\"very negative\",\"negative\",\"neutral\",\"positive\",\"very positive\"]\n",
    "    p_list = [\"--\",\"-\",\"0\",\"+\",\"++\"]\n",
    "    index2scores[label[i].item()] = p_list[p]\n",
    "#     index2scores[label[i].item()] = p\n",
    "for subtree in input.subtrees():\n",
    "    i = subtree.label()\n",
    "    subtree.set_label(index2scores[i])\n",
    "input.index2str()\n",
    "# TreeView(input)\n",
    "# TreeView(input)._cframe.print_to_file('output.ps')\n",
    "# https://stackoverflow.com/questions/23429117/saving-nltk-drawn-parse-tree-to-image-file\n",
    "# https://stackoverflow.com/questions/44880337/use-tkinter-for-nltk-draw-inside-of-jupyter-notebook\n",
    "# import os\n",
    "# os.system('magick output.ps output.png')\n",
    "# from IPython.display import Image\n",
    "# Image(filename='output.png')\n",
    "# input.pretty_print()\n",
    "outimage = TreePrettyPrinter(input)\n",
    "# text2png(outimage, 'test.png')\n",
    "outimage = str(outimage)\n",
    "print(outimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /?properties=%7B%22outputFormat%22%3A+%22json%22%2C+%22annotators%22%3A+%22tokenize%2Cpos%2Clemma%2Cssplit%2Cparse%22%2C+%22ssplit.ssplit.eolonly%22%3A+%22true%22%2C+%22tokenize.whitespace%22%3A+%22false%22%7D (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001578252C6A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。',))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    140\u001b[0m             conn = connection.create_connection(\n\u001b[1;32m--> 141\u001b[1;33m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] 由于目标计算机积极拒绝，无法连接。",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1238\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1284\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1233\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1234\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1025\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    963\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    965\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    149\u001b[0m             raise NewConnectionError(\n\u001b[1;32m--> 150\u001b[1;33m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x000001578252C6A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m                 )\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    638\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[1;32m--> 639\u001b[1;33m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[0;32m    640\u001b[0m             \u001b[0mretries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /?properties=%7B%22outputFormat%22%3A+%22json%22%2C+%22annotators%22%3A+%22tokenize%2Cpos%2Clemma%2Cssplit%2Cparse%22%2C+%22ssplit.ssplit.eolonly%22%3A+%22true%22%2C+%22tokenize.whitespace%22%3A+%22false%22%7D (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001578252C6A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。',))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-5a475e21c683>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmy_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"I love you.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_parse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# t.draw()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbinarize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# bt.draw()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\nltk\\parse\\corenlp.py\u001b[0m in \u001b[0;36mraw_parse\u001b[1;34m(self, sentence, properties, *args, **kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m         return next(\n\u001b[0;32m    228\u001b[0m             self.raw_parse_sents(\n\u001b[1;32m--> 229\u001b[1;33m                 \u001b[1;33m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_properties\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m             )\n\u001b[0;32m    231\u001b[0m         )\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\nltk\\parse\\corenlp.py\u001b[0m in \u001b[0;36mraw_parse_sents\u001b[1;34m(self, sentences, verbose, properties, *args, **kwargs)\u001b[0m\n\u001b[0;32m    282\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \"\"\"\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[0mparsed_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_properties\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mparsed_sent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparsed_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentences'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m             \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_sent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\nltk\\parse\\corenlp.py\u001b[0m in \u001b[0;36mapi_call\u001b[1;34m(self, data, properties)\u001b[0m\n\u001b[0;32m    245\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'properties'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_properties\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m             \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m         )\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mpost\u001b[1;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m         \"\"\"\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'POST'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    506\u001b[0m         }\n\u001b[0;32m    507\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    506\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /?properties=%7B%22outputFormat%22%3A+%22json%22%2C+%22annotators%22%3A+%22tokenize%2Cpos%2Clemma%2Cssplit%2Cparse%22%2C+%22ssplit.ssplit.eolonly%22%3A+%22true%22%2C+%22tokenize.whitespace%22%3A+%22false%22%7D (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001578252C6A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。',))"
     ]
    }
   ],
   "source": [
    "my_sentence = \"I love you.\"\n",
    "t, = parser.raw_parse(my_sentence)\n",
    "# t.draw()\n",
    "bt = binarize(t)\n",
    "# bt.draw()\n",
    "tree = bt.pformat()\n",
    "input = SenTreeTest.getTree(tree)\n",
    "# input.draw()\n",
    "model.eval()\n",
    "\n",
    "# print(type(dev[0]))\n",
    "# print(type(input))\n",
    "# model.forward(input)\n",
    "scores = model.forward(input).cpu()\n",
    "scores = scores.detach().numpy()\n",
    "\n",
    "# print(scores)\n",
    "scores_exp = np.exp(scores)\n",
    "possi = scores_exp / scores_exp.sum(axis=1).reshape(-1,1)\n",
    "# np.exp(possi)\n",
    "# print(scores_exp)\n",
    "# print(scores_exp.sum(axis = 1))\n",
    "# print(possi)\n",
    "\n",
    "plt.bar(['--','-','0','+','++'],possi[-1])\n",
    "plt.title(my_sentence)\n",
    "# plt.savefig(\"root graph1\" + '.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
